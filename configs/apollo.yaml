exp: 
  dir: ./exps # directory to save the experiment
  name: apollo # name of the experiment

datas:
  _target_: look2hear.datas.DataModule
  original_dir: train/original # dataset where the original audio files are stored
  codec_dir: train/codec # dataset where the codec audio files are stored
  codec_format: wav # the format of the codec audio files
  valid_dir: valid # dataset where the validation audio files are stored
  valid_original: original.wav # the original audio file name for validation
  valid_codec: codec.wav # the codec audio file name for validation
  codec:
    enable: false # enable auto generation of codec audio files, if enabled, the codec audio files will be generated. The codec_dir, codec_format will be ignored
    options:
      bitrate: random # random or fixed, if fixed, the bitrate will be set to the value of bitrate (int), if random, the bitrate will be randomly selected from [24000, 32000, 48000, 64000, 96000, 128000]
      compression: random # random or fixed, if fixed, the compression will be set to the value of compression (int), if random, the compression will be caculated by the bitrate
  sr: 44100 # sample rate
  segments: 3 # automatically cropped audio in seconds. The value should be less than the minimum audio duration
  num_steps: 1000 # number of samples to be used for training in one epoch.
  batch_size: 1 # batch size
  num_workers: 0 # number of workers for data loading
  pin_memory: true # pin memory for data loading

model:
  _target_: look2hear.models.apollo.Apollo
  sr: 44100 # sample rate
  win: 20 # ms
  feature_dim: 256 # feature dimension
  layer: 6 # number of layers

discriminator:
  _target_: look2hear.discriminators.frequencydis.MultiFrequencyDiscriminator
  nch: 2
  window: [32, 64, 128, 256, 512, 1024, 2048]

optimizer_g:
  _target_: torch.optim.AdamW
  lr: 0.001
  weight_decay: 0.01

optimizer_d:
  _target_: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0.01
  betas: [0.5, 0.99]

scheduler_g:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 2
  gamma: 0.98

scheduler_d:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 2
  gamma: 0.98

loss_g:
  _target_: look2hear.losses.gan_losses.MultiFrequencyGenLoss
  eps: 1e-8

loss_d:
  _target_: look2hear.losses.gan_losses.MultiFrequencyDisLoss
  eps: 1e-8

metrics:
  _target_: look2hear.losses.MultiSrcNegSDR
  sdr_type: sisdr

system:
  _target_: look2hear.system.audio_litmodule.AudioLightningModule

early_stopping:
  _target_: pytorch_lightning.callbacks.EarlyStopping
  monitor: val_loss
  patience: 20
  mode: min
  verbose: true

checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${exp.dir}/${exp.name}/checkpoints
  monitor: val_loss
  mode: min
  verbose: true
  save_top_k: 5
  save_last: true
  filename: '{epoch}-{val_loss:.4f}'

logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  name: ${exp.name}
  save_dir: ${exp.dir}/${exp.name}/logs
  offline: true # if true, the logs will not be uploaded to wandb
  project: Audio-Restoration

trainer:
  _target_: pytorch_lightning.Trainer
  devices: [0]
  max_epochs: 1000
  sync_batchnorm: true
  default_root_dir: ${exp.dir}/${exp.name}/
  accelerator: cuda
  limit_train_batches: 1.0
  fast_dev_run: false
  precision: bf16 # [16, bf16, 32, 64]